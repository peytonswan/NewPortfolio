[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Peyton Swan",
    "section": "",
    "text": "LinkedIn\n  \n  \n    \n     Github\n  \n\n  \n  \nCHANGE ME"
  },
  {
    "objectID": "projects/testingtutor.html",
    "href": "projects/testingtutor.html",
    "title": "Testing Tutor",
    "section": "",
    "text": "Testing Tutor is a research project I co-developed with my colleagues at University of Alabama and Augusta University and several undergraduate and graduate students to revolutionize the way students learn and practice software testing. It offers a dynamic environment where learners receive structured, actionable feedback while developing deeper conceptual understandings of testing principles.\nTesting Tutor reflects my passion for improving software engineering education by bridging the gap between practice and understanding through innovative, research-based tools.\n\n\nTesting Tutor addresses a fundamental challenge in computing education:\n&gt; How do we help students not just ‚Äúwrite tests,‚Äù but actually think like testers?\nThe system presents students with programming exercises and evaluates their test cases against underlying program behaviors. Rather than simply telling students what they missed, Testing Tutor encourages deeper learning through conceptual inquiry-based feedback.\n\n\n\n\nTwo Feedback Modes:\n\nTraditional Detailed Feedback: Similar to industrial tools, showing missing test cases and gaps in code coverage.\nInquiry-Based Conceptual Feedback: A novel mode that poses questions prompting students to reflect on their testing logic and gaps.\n\nAutomated Evaluation:\nStudents‚Äô test cases are automatically analyzed for correctness, completeness, and redundancy.\nStudent Growth Focus:\nEmphasizes metacognitive skills ‚Äî helping students understand why a test case is valuable, not just whether it passes.\nInstructor Dashboard:\nEnables educators to track student progress and adjust instruction based on common misconceptions.\n\n\n\n\nIn our study published in the Proceedings of the 52nd ACM Technical Symposium on Computer Science Education, we found:\n\nStudents who received conceptual feedback achieved higher code coverage.\nStudents wrote fewer redundant or unnecessary tests.\nStudents earned higher overall programming grades.\nStudents developed a stronger conceptual model of software testing.\nRead the full research paper\n\n\n\n\n\nMany traditional tools provide detailed but overwhelming feedback, encouraging trial-and-error rather than understanding.\nTesting Tutor helps close that gap by:\n\nTeaching test case design as a creative, critical thinking activity.\nEncouraging self-explanation and diagnostic reasoning.\nReducing reliance on guess-and-check strategies common among novice testers.\n\n\n\n\n\n\nExpansion to More Programming Languages: Supporting JavaScript, C++, and Python beyond current capabilities.\nDeeper Integration with Learning Management Systems (LMS): Embedding Testing Tutor directly into course workflows.\nGamified Feedback Loops: Adding achievement systems to reward thoughtful test design and conceptual breakthroughs.\n\n\n\n\n\n\nTesting Tutor Research Publication"
  },
  {
    "objectID": "projects/testingtutor.html#project-overview",
    "href": "projects/testingtutor.html#project-overview",
    "title": "Testing Tutor",
    "section": "",
    "text": "Testing Tutor addresses a fundamental challenge in computing education:\n&gt; How do we help students not just ‚Äúwrite tests,‚Äù but actually think like testers?\nThe system presents students with programming exercises and evaluates their test cases against underlying program behaviors. Rather than simply telling students what they missed, Testing Tutor encourages deeper learning through conceptual inquiry-based feedback."
  },
  {
    "objectID": "projects/testingtutor.html#key-features",
    "href": "projects/testingtutor.html#key-features",
    "title": "Testing Tutor",
    "section": "",
    "text": "Two Feedback Modes:\n\nTraditional Detailed Feedback: Similar to industrial tools, showing missing test cases and gaps in code coverage.\nInquiry-Based Conceptual Feedback: A novel mode that poses questions prompting students to reflect on their testing logic and gaps.\n\nAutomated Evaluation:\nStudents‚Äô test cases are automatically analyzed for correctness, completeness, and redundancy.\nStudent Growth Focus:\nEmphasizes metacognitive skills ‚Äî helping students understand why a test case is valuable, not just whether it passes.\nInstructor Dashboard:\nEnables educators to track student progress and adjust instruction based on common misconceptions."
  },
  {
    "objectID": "projects/testingtutor.html#research-outcomes",
    "href": "projects/testingtutor.html#research-outcomes",
    "title": "Testing Tutor",
    "section": "",
    "text": "In our study published in the Proceedings of the 52nd ACM Technical Symposium on Computer Science Education, we found:\n\nStudents who received conceptual feedback achieved higher code coverage.\nStudents wrote fewer redundant or unnecessary tests.\nStudents earned higher overall programming grades.\nStudents developed a stronger conceptual model of software testing.\nRead the full research paper"
  },
  {
    "objectID": "projects/testingtutor.html#why-it-matters",
    "href": "projects/testingtutor.html#why-it-matters",
    "title": "Testing Tutor",
    "section": "",
    "text": "Many traditional tools provide detailed but overwhelming feedback, encouraging trial-and-error rather than understanding.\nTesting Tutor helps close that gap by:\n\nTeaching test case design as a creative, critical thinking activity.\nEncouraging self-explanation and diagnostic reasoning.\nReducing reliance on guess-and-check strategies common among novice testers."
  },
  {
    "objectID": "projects/testingtutor.html#future-directions",
    "href": "projects/testingtutor.html#future-directions",
    "title": "Testing Tutor",
    "section": "",
    "text": "Expansion to More Programming Languages: Supporting JavaScript, C++, and Python beyond current capabilities.\nDeeper Integration with Learning Management Systems (LMS): Embedding Testing Tutor directly into course workflows.\nGamified Feedback Loops: Adding achievement systems to reward thoughtful test design and conceptual breakthroughs."
  },
  {
    "objectID": "projects/testingtutor.html#learn-more",
    "href": "projects/testingtutor.html#learn-more",
    "title": "Testing Tutor",
    "section": "",
    "text": "Testing Tutor Research Publication"
  },
  {
    "objectID": "projects/pedalogical.html",
    "href": "projects/pedalogical.html",
    "title": "Pedalogical",
    "section": "",
    "text": "Pedalogical is a research initiative I am leading at Willamette University, aimed at transforming the way we personalize education through artificial intelligence. Developed in collaboration with undergraduate and graduate students, Pedalogical leverages generative AI to create individualized learning experiences that are adaptive, scalable, and pedagogically sound.\nPedalogical is part of my broader research mission to advance computing education, interdisciplinary technology development, and ethical AI integration.\n\n\nThe core idea behind Pedalogical is simple but powerful:\n&gt; Use AI to dynamically generate assignments, explanations, and feedback based on each student‚Äôs unique knowledge and comprehension level.\nOur system integrates OpenAI‚Äôs GPT-4 models to assess students‚Äô understanding and produce customized educational materials tailored to their progress and needs.\nPedalogical is designed to:\n\nEnhance student engagement by meeting learners where they are.\nAlleviate instructor workload by automating parts of the content creation process.\nPromote deeper learning through individualized scaffolding and inquiry-based prompts.\n\n\n\n\n\nPersonalized Assignments:\nEach student receives tasks that reflect their individual strengths and areas for growth, moving beyond a ‚Äúone-size-fits-all‚Äù model.\nDynamic Explanations:\nExplanations adapt based on student responses and prior performance, helping students build conceptual understanding step-by-step.\nInstructor Insights:\nAggregate analytics offer instructors a clearer view of class-wide comprehension trends without overwhelming them with manual grading.\nEthical and Responsible AI Use:\nWe emphasize human-centered AI design principles, ensuring transparency, fairness, and respect for student autonomy.\n\n\n\n\nMy students were recognized at the 2025 Murdock College Science Research Conference, where they won a Poster Prize in the Neuroscience‚ÄìPsychology‚ÄìExercise Science category for their work on Pedalogical.\nOur interdisciplinary team demonstrated that AI can meaningfully enhance education when thoughtfully integrated with pedagogy.\n\n\n\n\nExpanding Content Domains: Moving beyond computing education into other fields such as biology, environmental science, and writing.\nAdaptive Feedback Loops: Developing real-time conversational tutoring agents that scaffold inquiry-based learning.\nOpen-Source Framework: Planning to release a toolkit for educators to customize and deploy their own versions of Pedalogical.\n\n\n\n\n\nWillamette University News Article on Pedalogical"
  },
  {
    "objectID": "projects/pedalogical.html#project-overview",
    "href": "projects/pedalogical.html#project-overview",
    "title": "Pedalogical",
    "section": "",
    "text": "The core idea behind Pedalogical is simple but powerful:\n&gt; Use AI to dynamically generate assignments, explanations, and feedback based on each student‚Äôs unique knowledge and comprehension level.\nOur system integrates OpenAI‚Äôs GPT-4 models to assess students‚Äô understanding and produce customized educational materials tailored to their progress and needs.\nPedalogical is designed to:\n\nEnhance student engagement by meeting learners where they are.\nAlleviate instructor workload by automating parts of the content creation process.\nPromote deeper learning through individualized scaffolding and inquiry-based prompts."
  },
  {
    "objectID": "projects/pedalogical.html#key-features",
    "href": "projects/pedalogical.html#key-features",
    "title": "Pedalogical",
    "section": "",
    "text": "Personalized Assignments:\nEach student receives tasks that reflect their individual strengths and areas for growth, moving beyond a ‚Äúone-size-fits-all‚Äù model.\nDynamic Explanations:\nExplanations adapt based on student responses and prior performance, helping students build conceptual understanding step-by-step.\nInstructor Insights:\nAggregate analytics offer instructors a clearer view of class-wide comprehension trends without overwhelming them with manual grading.\nEthical and Responsible AI Use:\nWe emphasize human-centered AI design principles, ensuring transparency, fairness, and respect for student autonomy."
  },
  {
    "objectID": "projects/pedalogical.html#outcomes-and-recognition",
    "href": "projects/pedalogical.html#outcomes-and-recognition",
    "title": "Pedalogical",
    "section": "",
    "text": "My students were recognized at the 2025 Murdock College Science Research Conference, where they won a Poster Prize in the Neuroscience‚ÄìPsychology‚ÄìExercise Science category for their work on Pedalogical.\nOur interdisciplinary team demonstrated that AI can meaningfully enhance education when thoughtfully integrated with pedagogy."
  },
  {
    "objectID": "projects/pedalogical.html#future-directions",
    "href": "projects/pedalogical.html#future-directions",
    "title": "Pedalogical",
    "section": "",
    "text": "Expanding Content Domains: Moving beyond computing education into other fields such as biology, environmental science, and writing.\nAdaptive Feedback Loops: Developing real-time conversational tutoring agents that scaffold inquiry-based learning.\nOpen-Source Framework: Planning to release a toolkit for educators to customize and deploy their own versions of Pedalogical."
  },
  {
    "objectID": "projects/pedalogical.html#learn-more",
    "href": "projects/pedalogical.html#learn-more",
    "title": "Pedalogical",
    "section": "",
    "text": "Willamette University News Article on Pedalogical"
  },
  {
    "objectID": "projects/individual-research-experience.html",
    "href": "projects/individual-research-experience.html",
    "title": "üéì For Students",
    "section": "",
    "text": "I regularly advise undergraduate and graduate students on research projects across a range of computing topics. If you‚Äôre a student interested in conducting research with me, read on to learn more about my research areas, expectations, and how to get started.\nLet‚Äôs turn your curiosity into original research!\n\n\nI supervise projects in a variety of areas including:\n\nüéì Computing Education Research (CER)\nü§ñ Artificial Intelligence in Education\nüß™ Software Testing and Feedback Systems\nüåê Interdisciplinary Applications of Computing\nüê¢ Conservation Technology and Data Science\n\nLearn more about my ongoing and past projects. I also welcome proposals in adjacent or new areas of computing‚Äîif you have an idea, let‚Äôs talk!\n\n\n\nStudents interested in research should begin by drafting a proposal and reaching out to me before the end of the semester prior to the semester in which they would like to begin. Proposals should follow this general outline:\n\n\n\nCredit Hours: Typically 2 or 4 credits depending on time commitment. (Non-credit research through a scholarship is also possible.)\nInitial Reading List: Include foundational articles or papers that identify a gap in knowledge.\nIntroductory Project: A small starting task to demonstrate your understanding and commitment, such as replicating prior work.\nProject Scope: Define what you aim to accomplish.\nWeekly Meetings: You‚Äôll meet with me regularly during the semester. These meetings are where we think, plan, and reflect together. As you come up with your proposal, consider:\n\nWhat do you hope to accomplish in our weekly meetings? How can I best support your growth as a researcher?\n\nTo help you frame your thinking, here are some common activities we often engage in:\n- Discuss literature and readings\n- Generate hypotheses or goals\n- Design methodology for data collection or experimentation\n- Analyze results and plan next steps\n- Review and revise your writing\n\n\n\n\nBy the end of the semester, students are expected to:\n\nSubmit a research paper in a format consistent with computing research publications\nGraduate students should aim for a conference or journal submission to disseminate their work and should minimally present at TechBytes\nUndergraduate students present at the Student Scholarship Recognition Day (SSRD), at TechBytes events, and should also aim for a conference or journal submission if possible\n\n\n\n\n\nBefore reaching out to begin an Individual Research Experience for credit or scholarship, you‚Äôll need to develop a research idea that aligns with your interests and has potential for meaningful investigation. This guide will help you get started.\n\n\nStart by considering broad themes that interest you. Some areas I actively work in include:\n\nüéì Computing Education Research (CER)\nü§ñ AI in Education & Generative Feedback\nüß™ Software Testing & Feedback Systems\nüåê Interdisciplinary Applications of Computing\nüê¢ Conservation Technology & Data Science\n\n\n\n\nAsk yourself:\n\nWhat bothers you in your field of study? What‚Äôs inefficient, unclear, or underexplored?\nHave you encountered a concept in a class that you‚Äôd like to understand better?\nIs there a tool or system that could be improved with computing?\nCan AI or data science contribute to a social, environmental, or educational cause you care about?\n\nJot down 2‚Äì3 questions or problems you‚Äôre curious about. Try to keep them broad at this stage.\n\n\n\nSearch Google Scholar, the ACM Digital Library, or arXiv to see:\n\nWhat others have done on this topic\nHow they‚Äôve framed their research questions\nWhat methods they‚Äôve used\n\nThis doesn‚Äôt have to be exhaustive‚Äîjust enough to ensure your idea is novel or builds meaningfully on existing work.\n\n\n\nBring a short, informal proposal when you first meet with me. It should include:\n\n\nA descriptive placeholder is fine. e.g., ‚ÄúUsing LLMs to Support Early CS Students with Auto-Graded Feedback‚Äù\n\n\n\nWhy is this topic important, timely, or interesting? What gap or problem are you hoping to address?\n\n\n\nState your main inquiry clearly. Examples:\n\nCan GPT-4 give helpful feedback on beginner Python assignments?\nHow do students interpret different types of automated feedback?\n\n\n\n\nHow will you explore this? Think about:\n\nData sources (real or synthetic)\nTools (e.g., GPT-4, Python, survey tools)\nMethods (e.g., prompt engineering, code analysis, surveys)\n\n\n\n\nWould you want to aim for a paper? Poster? Prototype? Public data release? Let‚Äôs set early goals.\n\n\n\nWhat help, access, or tools do you anticipate needing (e.g., GPT access, data, IRB approval)?\n\n\n\n\n\nOnce you‚Äôve drafted your initial idea, email me and we‚Äôll set up a meeting. We‚Äôll discuss:\n\nFeasibility\nRelevance to your interests and my expertise\nMilestones and weekly schedule\nDeliverables and expectations\n\nIf we agree to move forward, I‚Äôll help you refine the proposal and outline a formal plan for the term. Here‚Äôs a sample of what a fleshed out project might look like.\n\n\n\nPlease contact me before the end of the previous term that you wish to conduct research to give us time to plan. Proposals that involve human subjects (surveys, interviews, etc.) may require IRB approval, which can take time."
  },
  {
    "objectID": "projects/individual-research-experience.html#my-research-interests",
    "href": "projects/individual-research-experience.html#my-research-interests",
    "title": "üéì For Students",
    "section": "",
    "text": "I supervise projects in a variety of areas including:\n\nüéì Computing Education Research (CER)\nü§ñ Artificial Intelligence in Education\nüß™ Software Testing and Feedback Systems\nüåê Interdisciplinary Applications of Computing\nüê¢ Conservation Technology and Data Science\n\nLearn more about my ongoing and past projects. I also welcome proposals in adjacent or new areas of computing‚Äîif you have an idea, let‚Äôs talk!"
  },
  {
    "objectID": "projects/individual-research-experience.html#getting-started-proposing-a-research-project",
    "href": "projects/individual-research-experience.html#getting-started-proposing-a-research-project",
    "title": "üéì For Students",
    "section": "",
    "text": "Students interested in research should begin by drafting a proposal and reaching out to me before the end of the semester prior to the semester in which they would like to begin. Proposals should follow this general outline:\n\n\n\nCredit Hours: Typically 2 or 4 credits depending on time commitment. (Non-credit research through a scholarship is also possible.)\nInitial Reading List: Include foundational articles or papers that identify a gap in knowledge.\nIntroductory Project: A small starting task to demonstrate your understanding and commitment, such as replicating prior work.\nProject Scope: Define what you aim to accomplish.\nWeekly Meetings: You‚Äôll meet with me regularly during the semester. These meetings are where we think, plan, and reflect together. As you come up with your proposal, consider:\n\nWhat do you hope to accomplish in our weekly meetings? How can I best support your growth as a researcher?\n\nTo help you frame your thinking, here are some common activities we often engage in:\n- Discuss literature and readings\n- Generate hypotheses or goals\n- Design methodology for data collection or experimentation\n- Analyze results and plan next steps\n- Review and revise your writing\n\n\n\n\nBy the end of the semester, students are expected to:\n\nSubmit a research paper in a format consistent with computing research publications\nGraduate students should aim for a conference or journal submission to disseminate their work and should minimally present at TechBytes\nUndergraduate students present at the Student Scholarship Recognition Day (SSRD), at TechBytes events, and should also aim for a conference or journal submission if possible"
  },
  {
    "objectID": "projects/individual-research-experience.html#getting-started-on-a-proposal",
    "href": "projects/individual-research-experience.html#getting-started-on-a-proposal",
    "title": "üéì For Students",
    "section": "",
    "text": "Before reaching out to begin an Individual Research Experience for credit or scholarship, you‚Äôll need to develop a research idea that aligns with your interests and has potential for meaningful investigation. This guide will help you get started.\n\n\nStart by considering broad themes that interest you. Some areas I actively work in include:\n\nüéì Computing Education Research (CER)\nü§ñ AI in Education & Generative Feedback\nüß™ Software Testing & Feedback Systems\nüåê Interdisciplinary Applications of Computing\nüê¢ Conservation Technology & Data Science\n\n\n\n\nAsk yourself:\n\nWhat bothers you in your field of study? What‚Äôs inefficient, unclear, or underexplored?\nHave you encountered a concept in a class that you‚Äôd like to understand better?\nIs there a tool or system that could be improved with computing?\nCan AI or data science contribute to a social, environmental, or educational cause you care about?\n\nJot down 2‚Äì3 questions or problems you‚Äôre curious about. Try to keep them broad at this stage.\n\n\n\nSearch Google Scholar, the ACM Digital Library, or arXiv to see:\n\nWhat others have done on this topic\nHow they‚Äôve framed their research questions\nWhat methods they‚Äôve used\n\nThis doesn‚Äôt have to be exhaustive‚Äîjust enough to ensure your idea is novel or builds meaningfully on existing work.\n\n\n\nBring a short, informal proposal when you first meet with me. It should include:\n\n\nA descriptive placeholder is fine. e.g., ‚ÄúUsing LLMs to Support Early CS Students with Auto-Graded Feedback‚Äù\n\n\n\nWhy is this topic important, timely, or interesting? What gap or problem are you hoping to address?\n\n\n\nState your main inquiry clearly. Examples:\n\nCan GPT-4 give helpful feedback on beginner Python assignments?\nHow do students interpret different types of automated feedback?\n\n\n\n\nHow will you explore this? Think about:\n\nData sources (real or synthetic)\nTools (e.g., GPT-4, Python, survey tools)\nMethods (e.g., prompt engineering, code analysis, surveys)\n\n\n\n\nWould you want to aim for a paper? Poster? Prototype? Public data release? Let‚Äôs set early goals.\n\n\n\nWhat help, access, or tools do you anticipate needing (e.g., GPT access, data, IRB approval)?"
  },
  {
    "objectID": "projects/individual-research-experience.html#what-happens-next",
    "href": "projects/individual-research-experience.html#what-happens-next",
    "title": "üéì For Students",
    "section": "",
    "text": "Once you‚Äôve drafted your initial idea, email me and we‚Äôll set up a meeting. We‚Äôll discuss:\n\nFeasibility\nRelevance to your interests and my expertise\nMilestones and weekly schedule\nDeliverables and expectations\n\nIf we agree to move forward, I‚Äôll help you refine the proposal and outline a formal plan for the term. Here‚Äôs a sample of what a fleshed out project might look like."
  },
  {
    "objectID": "projects/individual-research-experience.html#tip-reach-out-early",
    "href": "projects/individual-research-experience.html#tip-reach-out-early",
    "title": "üéì For Students",
    "section": "",
    "text": "Please contact me before the end of the previous term that you wish to conduct research to give us time to plan. Proposals that involve human subjects (surveys, interviews, etc.) may require IRB approval, which can take time."
  },
  {
    "objectID": "ai-learning-circle/index.html",
    "href": "ai-learning-circle/index.html",
    "title": "ü§ñ AI Learning Circle",
    "section": "",
    "text": "üë©‚Äçüè´ Members: L.Cordova, V.Pham, M.McKissack, F.Agbo üìÖ Semester: Summer 2025\nüìç Location: Virtual\n\n\n\n\n\n\nWeek\nTopic\nMaterial\n\n\n\n\n1\nIntroduction\noutline | slides\n\n\n2\nPrompt Engineering and Integration Brainstorming\noutline | slides\n\n\n3\n\n\n\n\n4\n\n\n\n\n5\n\n\n\n\n6\n\n\n\n\n\n\n\n\n\nLearning Objectives\n\nDesire to identify and evaluate AI tools appropriate for integration into curriculum, especially for introductory courses.\nInterest in ethical usage of generative AI and understanding its underlying logic.\nAim to connect AI tools across disciplines and ensure accessibility.\nDesire to understand and improve the impact of AI on student engagement and learning outcomes.\nExplore pedagogical best practices for classroom AI integration.\n\nSpecific Goals for This Learning Circle\n\nCreate a toolkit for AI integration, including course shells, syllabi, and sample activities.\nDevelop frameworks or criteria for when and how to use AI in coursework.\nSupport institutional sharing by preparing material for broader faculty adoption.\nGather tools and ideas to support faculty across different schools and disciplines.\n\nTeaching Enhancements\n\nEnhance student engagement and equip them with decision-making skills on when to use AI.\nLearn practical strategies from peers for classroom AI usage and support accessibility.\nImprove structured AI integration into lectures, activities, and assignments.\nIncrease confidence and effectiveness in teaching with AI.\n\nScholarship Enhancements\n\nLeverage the experience to support scholarly communication and faculty collaboration.\nUse the knowledge to better support faculty and student understanding of AI methods.\nPotential use of AI for creative endeavors, even if not current research focus.\nBuild confidence in articulating practical implications of AI in education.\n\nService Enhancements\n\nContribute to institutional initiatives like ‚ÄúAI Across the Curriculum.‚Äù\nFacilitate collaboration between different campuses and programs.\nEngage faculty and help shape the broader institutional understanding and application of AI.\nProvide concrete case scenarios to support assessment frameworks for AI learning outcomes.\n\n\n\n\n\n\n‚Ä¶"
  },
  {
    "objectID": "ai-learning-circle/index.html#weekly-topics",
    "href": "ai-learning-circle/index.html#weekly-topics",
    "title": "ü§ñ AI Learning Circle",
    "section": "",
    "text": "Week\nTopic\nMaterial\n\n\n\n\n1\nIntroduction\noutline | slides\n\n\n2\nPrompt Engineering and Integration Brainstorming\noutline | slides\n\n\n3\n\n\n\n\n4\n\n\n\n\n5\n\n\n\n\n6"
  },
  {
    "objectID": "ai-learning-circle/index.html#objectives",
    "href": "ai-learning-circle/index.html#objectives",
    "title": "ü§ñ AI Learning Circle",
    "section": "",
    "text": "Learning Objectives\n\nDesire to identify and evaluate AI tools appropriate for integration into curriculum, especially for introductory courses.\nInterest in ethical usage of generative AI and understanding its underlying logic.\nAim to connect AI tools across disciplines and ensure accessibility.\nDesire to understand and improve the impact of AI on student engagement and learning outcomes.\nExplore pedagogical best practices for classroom AI integration.\n\nSpecific Goals for This Learning Circle\n\nCreate a toolkit for AI integration, including course shells, syllabi, and sample activities.\nDevelop frameworks or criteria for when and how to use AI in coursework.\nSupport institutional sharing by preparing material for broader faculty adoption.\nGather tools and ideas to support faculty across different schools and disciplines.\n\nTeaching Enhancements\n\nEnhance student engagement and equip them with decision-making skills on when to use AI.\nLearn practical strategies from peers for classroom AI usage and support accessibility.\nImprove structured AI integration into lectures, activities, and assignments.\nIncrease confidence and effectiveness in teaching with AI.\n\nScholarship Enhancements\n\nLeverage the experience to support scholarly communication and faculty collaboration.\nUse the knowledge to better support faculty and student understanding of AI methods.\nPotential use of AI for creative endeavors, even if not current research focus.\nBuild confidence in articulating practical implications of AI in education.\n\nService Enhancements\n\nContribute to institutional initiatives like ‚ÄúAI Across the Curriculum.‚Äù\nFacilitate collaboration between different campuses and programs.\nEngage faculty and help shape the broader institutional understanding and application of AI.\nProvide concrete case scenarios to support assessment frameworks for AI learning outcomes."
  },
  {
    "objectID": "ai-learning-circle/index.html#resourceslinks",
    "href": "ai-learning-circle/index.html#resourceslinks",
    "title": "ü§ñ AI Learning Circle",
    "section": "",
    "text": "‚Ä¶"
  },
  {
    "objectID": "ai-learning-circle/content/meeting-2.html",
    "href": "ai-learning-circle/content/meeting-2.html",
    "title": "Meeting 2: Prompt Engineering and Integration Brainstorming",
    "section": "",
    "text": "Pedagogical Use Cases of AI\n\nPrompt Engineering Strategies for Learning\n\nExploring Generative AI Providers for Canvas Integration\n\nGroup Reflection & Discussion\n\n\n\n\nRecent study: Not All Chatbots Teach\n\nCompared a structured, outcome-aligned chatbot vs.¬†a generic LLM wrapper\nKey finding: Structured AI tools significantly improved student performance and clarity in software testing tasks\n\n\n\n\n\nStructure and scaffolding matter\nAlignment with learning outcomes is crucial\nPromotes metacognition and reduces surface-level AI use\n\n\n\n\nQuestions:\n\nWhere have you seen AI help or hinder student learning?\nWhat risks or opportunities do you see in using AI inside your own course context?"
  },
  {
    "objectID": "ai-learning-circle/content/meeting-2.html#case-study-not-all-chatbots-teach",
    "href": "ai-learning-circle/content/meeting-2.html#case-study-not-all-chatbots-teach",
    "title": "Meeting 2: Prompt Engineering and Integration Brainstorming",
    "section": "",
    "text": "Recent study: Not All Chatbots Teach\n\nCompared a structured, outcome-aligned chatbot vs.¬†a generic LLM wrapper\nKey finding: Structured AI tools significantly improved student performance and clarity in software testing tasks"
  },
  {
    "objectID": "ai-learning-circle/content/meeting-2.html#implications-for-teaching",
    "href": "ai-learning-circle/content/meeting-2.html#implications-for-teaching",
    "title": "Meeting 2: Prompt Engineering and Integration Brainstorming",
    "section": "",
    "text": "Structure and scaffolding matter\nAlignment with learning outcomes is crucial\nPromotes metacognition and reduces surface-level AI use"
  },
  {
    "objectID": "ai-learning-circle/content/meeting-2.html#reflect-discuss",
    "href": "ai-learning-circle/content/meeting-2.html#reflect-discuss",
    "title": "Meeting 2: Prompt Engineering and Integration Brainstorming",
    "section": "",
    "text": "Questions:\n\nWhere have you seen AI help or hinder student learning?\nWhat risks or opportunities do you see in using AI inside your own course context?"
  },
  {
    "objectID": "ai-learning-circle/content/meeting-2.html#using-prompts-as-guardrails",
    "href": "ai-learning-circle/content/meeting-2.html#using-prompts-as-guardrails",
    "title": "Meeting 2: Prompt Engineering and Integration Brainstorming",
    "section": "Using Prompts as Guardrails",
    "text": "Using Prompts as Guardrails\n\nInstructor-written prompts can:\n\nSet boundaries (academic integrity, tone, focus)\nScaffold learning (step-by-step guidance, Socratic questioning)\nEncourage metacognition (reflect on process)"
  },
  {
    "objectID": "ai-learning-circle/content/meeting-2.html#prompt-examples",
    "href": "ai-learning-circle/content/meeting-2.html#prompt-examples",
    "title": "Meeting 2: Prompt Engineering and Integration Brainstorming",
    "section": "Prompt Examples",
    "text": "Prompt Examples\n\n‚ÄúAsk the student questions to deepen their understanding of X.‚Äù\n‚ÄúYou are a peer reviewer. Give friendly but rigorous feedback on their code.‚Äù\n‚ÄúUse the Feynman Technique to help the student clarify their concept.‚Äù"
  },
  {
    "objectID": "ai-learning-circle/content/meeting-2.html#reflect-discuss-1",
    "href": "ai-learning-circle/content/meeting-2.html#reflect-discuss-1",
    "title": "Meeting 2: Prompt Engineering and Integration Brainstorming",
    "section": "Reflect & Discuss",
    "text": "Reflect & Discuss\nQuestions:\n\nWhat kind of prompts might support your students‚Äô learning?\nHow can prompt templates become reusable teaching assets?"
  },
  {
    "objectID": "ai-learning-circle/content/meeting-2.html#major-providers",
    "href": "ai-learning-circle/content/meeting-2.html#major-providers",
    "title": "Meeting 2: Prompt Engineering and Integration Brainstorming",
    "section": "Major Providers",
    "text": "Major Providers\n\n\n\n\n\n\n\nProvider\nNotes\n\n\n\n\nOpenAI\nGPT-4o, API access, supports embeddings, used widely\n\n\nGemini\nGoogle‚Äôs LLM, integrated into Google Workspace, strong data privacy controls\n\n\nAnthropic Claude\nEmphasizes safety and guardrails\n\n\nCohere, Mistral, HuggingFace\nResearch/community focused, fine-tuning support"
  },
  {
    "objectID": "ai-learning-circle/content/meeting-2.html#building-custom-chatbots-for-canvas",
    "href": "ai-learning-circle/content/meeting-2.html#building-custom-chatbots-for-canvas",
    "title": "Meeting 2: Prompt Engineering and Integration Brainstorming",
    "section": "Building Custom Chatbots for Canvas",
    "text": "Building Custom Chatbots for Canvas\nüõ†Ô∏è Options include:\n\nOpenAI Functions + Flask/FastAPI backend\n\nGoogle Cloud Vertex AI with Gemini + Dialogflow\n\nCustom wrappers using LangChain or Semantic Kernel\n\nEmbed into Canvas via LTI tools, iframes, or static tools"
  },
  {
    "objectID": "ai-learning-circle/content/meeting-2.html#reflect-discuss-2",
    "href": "ai-learning-circle/content/meeting-2.html#reflect-discuss-2",
    "title": "Meeting 2: Prompt Engineering and Integration Brainstorming",
    "section": "Reflect & Discuss",
    "text": "Reflect & Discuss\nQuestions:\n\nWhat role could a chatbot play in your course?\nWould it be formative, summative, exploratory?\nWhat barriers do you foresee?"
  },
  {
    "objectID": "ai-learning-circle/slides/meeting-2.html",
    "href": "ai-learning-circle/slides/meeting-2.html",
    "title": "Meeting 2: Prompt Engineering and Integration Brainstorming",
    "section": "",
    "text": "Announcements\n\n\n\nNone today. Hurray!"
  },
  {
    "objectID": "ai-learning-circle/slides/meeting-2.html#case-study-not-all-chatbots-teach",
    "href": "ai-learning-circle/slides/meeting-2.html#case-study-not-all-chatbots-teach",
    "title": "Meeting 2: Prompt Engineering and Integration Brainstorming",
    "section": "Case Study: Not All Chatbots Teach",
    "text": "Case Study: Not All Chatbots Teach\n\nRecent study: Not All Chatbots Teach\n\nCompared a structured, outcome-aligned chatbot vs.¬†a generic LLM wrapper\nKey finding: Structured AI tools significantly improved student performance and clarity in software testing tasks"
  },
  {
    "objectID": "ai-learning-circle/slides/meeting-2.html#implications-for-teaching",
    "href": "ai-learning-circle/slides/meeting-2.html#implications-for-teaching",
    "title": "Meeting 2: Prompt Engineering and Integration Brainstorming",
    "section": "Implications for Teaching",
    "text": "Implications for Teaching\n\nStructure and scaffolding matter\nAlignment with learning outcomes is crucial\nPromotes metacognition and reduces surface-level AI use"
  },
  {
    "objectID": "ai-learning-circle/slides/meeting-2.html#reflect-discuss",
    "href": "ai-learning-circle/slides/meeting-2.html#reflect-discuss",
    "title": "Meeting 2: Prompt Engineering and Integration Brainstorming",
    "section": "Reflect & Discuss",
    "text": "Reflect & Discuss\nQuestions:\n\nWhere have you seen AI help or hinder student learning?\nWhat risks or opportunities do you see in using AI inside your own course context?"
  },
  {
    "objectID": "ai-learning-circle/slides/meeting-2.html#using-prompts-as-guardrails",
    "href": "ai-learning-circle/slides/meeting-2.html#using-prompts-as-guardrails",
    "title": "Meeting 2: Prompt Engineering and Integration Brainstorming",
    "section": "Using Prompts as Guardrails",
    "text": "Using Prompts as Guardrails\n\nInstructor-written prompts can:\n\nSet boundaries (academic integrity, tone, focus)\nScaffold learning (step-by-step guidance, Socratic questioning)\nEncourage metacognition (reflect on process)"
  },
  {
    "objectID": "ai-learning-circle/slides/meeting-2.html#prompt-examples",
    "href": "ai-learning-circle/slides/meeting-2.html#prompt-examples",
    "title": "Meeting 2: Prompt Engineering and Integration Brainstorming",
    "section": "Prompt Examples",
    "text": "Prompt Examples\n\n‚ÄúAsk the student questions to deepen their understanding of X.‚Äù\n‚ÄúYou are a peer reviewer. Give friendly but rigorous feedback on their code.‚Äù\n‚ÄúUse the Feynman Technique to help the student clarify their concept.‚Äù"
  },
  {
    "objectID": "ai-learning-circle/slides/meeting-2.html#reflect-discuss-1",
    "href": "ai-learning-circle/slides/meeting-2.html#reflect-discuss-1",
    "title": "Meeting 2: Prompt Engineering and Integration Brainstorming",
    "section": "Reflect & Discuss",
    "text": "Reflect & Discuss\nQuestions:\n\nWhat kind of prompts might support your students‚Äô learning?\nHow can prompt templates become reusable teaching assets?"
  },
  {
    "objectID": "ai-learning-circle/slides/meeting-2.html#major-providers",
    "href": "ai-learning-circle/slides/meeting-2.html#major-providers",
    "title": "Meeting 2: Prompt Engineering and Integration Brainstorming",
    "section": "Major Providers",
    "text": "Major Providers\n\n\n\n\n\n\n\nProvider\nNotes\n\n\n\n\nOpenAI\nGPT-4o, API access, supports embeddings, used widely\n\n\nGemini\nGoogle‚Äôs LLM, integrated into Google Workspace, strong data privacy controls\n\n\nAnthropic Claude\nEmphasizes safety and guardrails\n\n\nCohere, Mistral, HuggingFace\nResearch/community focused, fine-tuning support"
  },
  {
    "objectID": "ai-learning-circle/slides/meeting-2.html#building-custom-chatbots-for-canvas",
    "href": "ai-learning-circle/slides/meeting-2.html#building-custom-chatbots-for-canvas",
    "title": "Meeting 2: Prompt Engineering and Integration Brainstorming",
    "section": "Building Custom Chatbots for Canvas",
    "text": "Building Custom Chatbots for Canvas\nüõ†Ô∏è Options include:\n\nOpenAI Functions + Flask/FastAPI backend\n\nGoogle Cloud Vertex AI with Gemini + Dialogflow\n\nCustom wrappers using LangChain or Semantic Kernel\n\nEmbed into Canvas via LTI tools, iframes, or static tools"
  },
  {
    "objectID": "ai-learning-circle/slides/meeting-2.html#reflect-discuss-2",
    "href": "ai-learning-circle/slides/meeting-2.html#reflect-discuss-2",
    "title": "Meeting 2: Prompt Engineering and Integration Brainstorming",
    "section": "Reflect & Discuss",
    "text": "Reflect & Discuss\nQuestions:\n\nWhat role could a chatbot play in your course?\nWould it be formative, summative, exploratory?\nWhat barriers do you foresee?"
  },
  {
    "objectID": "projects/oregonturtles.html",
    "href": "projects/oregonturtles.html",
    "title": "Oregon Turtles",
    "section": "",
    "text": "The Oregon Turtle Project is an interdisciplinary initiative I worked on with Dr.¬†Gareth Hopkins. The projectintegrates computer science and ecology in support of wildlife conservation. Focused on Oregon‚Äôs two native freshwater turtle species, the project demonstrates how technology can drive real-world environmental impact.\nThe Oregon Turtle Project reflects my belief that technology, when thoughtfully applied, can play a transformative role in solving environmental and societal challenges.\n\n\nNative turtle populations in Oregon, including the Western Pond Turtle (Actinemys marmorata) and the Western Painted Turtle (Chrysemys picta bellii), face growing threats from habitat loss, invasive species, and environmental changes.\nThe Oregon Turtle Project addresses these challenges by leveraging digital tools for efficient, accurate conservation data collection.\n\n\n\nOur mission is to:\n\nStreamline Field Data Collection: Develop mobile-friendly, digital survey tools to replace traditional paper-based methods. The Oregon Turtle Project shows how interdisciplinary collaboration can create innovative solutions to urgent conservation challenges.\nEmpower Citizen Scientists: Provide easy-to-use platforms for the public to report turtle sightings and habitat conditions.\nEnhance Data Quality and Access: Centralize ecological observations into accessible, analyzable datasets to better inform conservation efforts.\n\n\n\n\nA cornerstone of this project is student mentorship.\nThrough the Oregon Turtle Project, I mentored computer science students in:\n\nFull-stack software development for field research applications\nData science and ecological data management\nInterdisciplinary teamwork with biologists and conservationists\n\nStudents gained hands-on experience building systems that directly impact biodiversity preservation efforts.\n\n\n\nThe Oregon Turtle Project is more than a conservation tool ‚Äî it is a model for how computer science can be applied beyond traditional industry contexts.\nBy bridging environmental science and technology, we are:\n\nImproving the quality of ecological research data\nReducing the administrative burden on field scientists\nCreating opportunities for public engagement in conservation\n\n\n\n\n\nExpansion to Other At-Risk Species:\nAdapting our digital tools for broader use across multiple conservation initiatives.\nIntegration with GIS Systems:\nIncorporating spatial mapping to visualize turtle habitats and migration patterns.\nPredictive Modeling:\nUsing collected data to forecast habitat threats and support proactive conservation strategies.\n\n\n\n\n\nOregon Turtles Conservation Organization"
  },
  {
    "objectID": "projects/oregonturtles.html#project-overview",
    "href": "projects/oregonturtles.html#project-overview",
    "title": "Oregon Turtles",
    "section": "",
    "text": "Native turtle populations in Oregon, including the Western Pond Turtle (Actinemys marmorata) and the Western Painted Turtle (Chrysemys picta bellii), face growing threats from habitat loss, invasive species, and environmental changes.\nThe Oregon Turtle Project addresses these challenges by leveraging digital tools for efficient, accurate conservation data collection."
  },
  {
    "objectID": "projects/oregonturtles.html#goals-and-approach",
    "href": "projects/oregonturtles.html#goals-and-approach",
    "title": "Oregon Turtles",
    "section": "",
    "text": "Our mission is to:\n\nStreamline Field Data Collection: Develop mobile-friendly, digital survey tools to replace traditional paper-based methods. The Oregon Turtle Project shows how interdisciplinary collaboration can create innovative solutions to urgent conservation challenges.\nEmpower Citizen Scientists: Provide easy-to-use platforms for the public to report turtle sightings and habitat conditions.\nEnhance Data Quality and Access: Centralize ecological observations into accessible, analyzable datasets to better inform conservation efforts."
  },
  {
    "objectID": "projects/oregonturtles.html#student-engagement",
    "href": "projects/oregonturtles.html#student-engagement",
    "title": "Oregon Turtles",
    "section": "",
    "text": "A cornerstone of this project is student mentorship.\nThrough the Oregon Turtle Project, I mentored computer science students in:\n\nFull-stack software development for field research applications\nData science and ecological data management\nInterdisciplinary teamwork with biologists and conservationists\n\nStudents gained hands-on experience building systems that directly impact biodiversity preservation efforts."
  },
  {
    "objectID": "projects/oregonturtles.html#broader-impact",
    "href": "projects/oregonturtles.html#broader-impact",
    "title": "Oregon Turtles",
    "section": "",
    "text": "The Oregon Turtle Project is more than a conservation tool ‚Äî it is a model for how computer science can be applied beyond traditional industry contexts.\nBy bridging environmental science and technology, we are:\n\nImproving the quality of ecological research data\nReducing the administrative burden on field scientists\nCreating opportunities for public engagement in conservation"
  },
  {
    "objectID": "projects/oregonturtles.html#future-directions",
    "href": "projects/oregonturtles.html#future-directions",
    "title": "Oregon Turtles",
    "section": "",
    "text": "Expansion to Other At-Risk Species:\nAdapting our digital tools for broader use across multiple conservation initiatives.\nIntegration with GIS Systems:\nIncorporating spatial mapping to visualize turtle habitats and migration patterns.\nPredictive Modeling:\nUsing collected data to forecast habitat threats and support proactive conservation strategies."
  },
  {
    "objectID": "projects/oregonturtles.html#learn-more",
    "href": "projects/oregonturtles.html#learn-more",
    "title": "Oregon Turtles",
    "section": "",
    "text": "Oregon Turtles Conservation Organization"
  },
  {
    "objectID": "projects/sample-project.html",
    "href": "projects/sample-project.html",
    "title": "Sample Research Project",
    "section": "",
    "text": "The following is a sample project proposal for an independent research experience that we have developed after your initial proposal.\n\n\n\n\n\n\nNote\n\n\n\nThis specific type of project discusses the possible usage of actual student data and would require Institutional Review Board (IRB) approval. A project including human subjects and/or their data would need to have to be proposed the semester prior to the start of the project in order to allow time for the IRB process.\n\n\n\n\nInstructor: Lucas P. Cordova, Ph.D.\nEmail: lpcordova@willamette.edu\nTerm: Summer 2025 (11 Weeks Undergrad or 14 Weeks Grad)\nCredit Hours: 4\n\n\n\nThis independent graduate research experience focuses on the application of large language models (LLMs), specifically GPT-4, to improve scalability and quality in formative feedback for professional and workplace-integrated computing education. The student will evaluate generative AI‚Äôs role in augmenting instructional feedback at scale‚Äîparticularly for code correctness, style, and documentation‚Äîand produce dissemination-ready deliverables suitable for academic or industry-facing venues.\n\n\n\nThe project will culminate in the production of a conference-ready paper, industry white paper, or field-specific dissemination resource, with a potential submission target including venues such as SIGCSE, IEEE EDUCON, or practitioner conferences related to software engineering education and workplace learning.\n\n\n\n\nEvaluate the utility of generative AI feedback systems for professional computing learners\nCompare GPT-4 feedback to human reviewer standards (e.g., TAs, instructors, peer mentors)\nInvestigate how prompt engineering and rubric alignment affect feedback quality and relevance\nIdentify limitations or ethical challenges in applying LLMs in high-stakes or career-critical environments\n\n\n\n\n\n‚ÄúLarge Language Models as Programming Assistants‚Äù (Chen et al.)\n‚ÄúAutomated Feedback in Computer Science Education‚Äù (Piech et al.)\n‚ÄúThe Effect of AI Feedback on Learning in Online Programming Environments‚Äù (recent CHI or L@S papers)\nIndustry white papers on AI-based developer tools (e.g., GitHub Copilot, Amazon CodeWhisperer)\n\n\n\n\nReconstruct a baseline automated feedback pipeline using GPT-4 on real or simulated student code submissions. Annotate and evaluate generated feedback using a rubric derived from professional coding standards and educational best practices.\n\n\n\nThe project is based on conducting research during the Summer semester and will be divided into 11 weeks for undergraduate students or 14 weeks for graduate students. The timeline below outlines the major phases of the project, including key milestones and deliverables. A graduate version of the timeline will include additional weeks for literature review, dataset definition, and analysis.\nWeeks 1‚Äì2: Contextualization and Literature Review\n\nIdentify a target dissemination venue (conference, journal, white paper audience)\nReview literature on AI-generated feedback in education and industry\nExplore empirical methods used in LLM studies and feedback evaluation\n\nWeeks 3‚Äì4: Dataset Definition and Evaluation Criteria\n\nSelect or simulate a dataset of professional-quality code submissions\nDefine rubrics and evaluation metrics (clarity, correctness, tone, etc.)\nSet up annotation tools or benchmarking criteria\n\nWeeks 5‚Äì7: Implementation and Feedback Generation\n\nDesign and refine GPT-4 prompts for feedback generation\nRun experiments across different coding contexts and prompt strategies\nCollect and log feedback output, including anomalies or inconsistencies\n\nWeeks 8‚Äì9: Analysis and Interpretation\n\nConduct thematic analysis and comparative evaluation of feedback\nIdentify trends, strengths, and weaknesses in generative output\nEvaluate against human feedback if available\n\nWeeks 10‚Äì11: Synthesis and Dissemination\n\nDraft paper, poster, or industry report with figures and analysis\nPrepare slides and present to faculty, at TechBytes, or a relevant audience\nRevise deliverables based on feedback and prepare for submission\n\n\n\n\n\nDesign and execute an applied research study with professional relevance\nGain experience in field-appropriate dissemination and communication\nDevelop evaluation frameworks for AI-in-the-loop tools in computing education\nContribute to the understanding of responsible AI use in real-world learning contexts\n\n\n\n\n\nA dissemination-ready deliverable (e.g., paper, white paper, presentation)\nAnnotated dataset and reproducible experimentation code\nSummary presentation for presenting to faculty and students at TechBytes and/or practitioner audience"
  },
  {
    "objectID": "projects/sample-project.html#generative-ai-for-scalable-feedback-in-professional-computing-education",
    "href": "projects/sample-project.html#generative-ai-for-scalable-feedback-in-professional-computing-education",
    "title": "Sample Research Project",
    "section": "",
    "text": "Instructor: Lucas P. Cordova, Ph.D.\nEmail: lpcordova@willamette.edu\nTerm: Summer 2025 (11 Weeks Undergrad or 14 Weeks Grad)\nCredit Hours: 4"
  },
  {
    "objectID": "projects/sample-project.html#project-focus",
    "href": "projects/sample-project.html#project-focus",
    "title": "Sample Research Project",
    "section": "",
    "text": "This independent graduate research experience focuses on the application of large language models (LLMs), specifically GPT-4, to improve scalability and quality in formative feedback for professional and workplace-integrated computing education. The student will evaluate generative AI‚Äôs role in augmenting instructional feedback at scale‚Äîparticularly for code correctness, style, and documentation‚Äîand produce dissemination-ready deliverables suitable for academic or industry-facing venues."
  },
  {
    "objectID": "projects/sample-project.html#target-outcome",
    "href": "projects/sample-project.html#target-outcome",
    "title": "Sample Research Project",
    "section": "",
    "text": "The project will culminate in the production of a conference-ready paper, industry white paper, or field-specific dissemination resource, with a potential submission target including venues such as SIGCSE, IEEE EDUCON, or practitioner conferences related to software engineering education and workplace learning."
  },
  {
    "objectID": "projects/sample-project.html#research-objectives",
    "href": "projects/sample-project.html#research-objectives",
    "title": "Sample Research Project",
    "section": "",
    "text": "Evaluate the utility of generative AI feedback systems for professional computing learners\nCompare GPT-4 feedback to human reviewer standards (e.g., TAs, instructors, peer mentors)\nInvestigate how prompt engineering and rubric alignment affect feedback quality and relevance\nIdentify limitations or ethical challenges in applying LLMs in high-stakes or career-critical environments"
  },
  {
    "objectID": "projects/sample-project.html#background-readings",
    "href": "projects/sample-project.html#background-readings",
    "title": "Sample Research Project",
    "section": "",
    "text": "‚ÄúLarge Language Models as Programming Assistants‚Äù (Chen et al.)\n‚ÄúAutomated Feedback in Computer Science Education‚Äù (Piech et al.)\n‚ÄúThe Effect of AI Feedback on Learning in Online Programming Environments‚Äù (recent CHI or L@S papers)\nIndustry white papers on AI-based developer tools (e.g., GitHub Copilot, Amazon CodeWhisperer)"
  },
  {
    "objectID": "projects/sample-project.html#preliminary-assignment",
    "href": "projects/sample-project.html#preliminary-assignment",
    "title": "Sample Research Project",
    "section": "",
    "text": "Reconstruct a baseline automated feedback pipeline using GPT-4 on real or simulated student code submissions. Annotate and evaluate generated feedback using a rubric derived from professional coding standards and educational best practices."
  },
  {
    "objectID": "projects/sample-project.html#timeline-and-deliverables",
    "href": "projects/sample-project.html#timeline-and-deliverables",
    "title": "Sample Research Project",
    "section": "",
    "text": "The project is based on conducting research during the Summer semester and will be divided into 11 weeks for undergraduate students or 14 weeks for graduate students. The timeline below outlines the major phases of the project, including key milestones and deliverables. A graduate version of the timeline will include additional weeks for literature review, dataset definition, and analysis.\nWeeks 1‚Äì2: Contextualization and Literature Review\n\nIdentify a target dissemination venue (conference, journal, white paper audience)\nReview literature on AI-generated feedback in education and industry\nExplore empirical methods used in LLM studies and feedback evaluation\n\nWeeks 3‚Äì4: Dataset Definition and Evaluation Criteria\n\nSelect or simulate a dataset of professional-quality code submissions\nDefine rubrics and evaluation metrics (clarity, correctness, tone, etc.)\nSet up annotation tools or benchmarking criteria\n\nWeeks 5‚Äì7: Implementation and Feedback Generation\n\nDesign and refine GPT-4 prompts for feedback generation\nRun experiments across different coding contexts and prompt strategies\nCollect and log feedback output, including anomalies or inconsistencies\n\nWeeks 8‚Äì9: Analysis and Interpretation\n\nConduct thematic analysis and comparative evaluation of feedback\nIdentify trends, strengths, and weaknesses in generative output\nEvaluate against human feedback if available\n\nWeeks 10‚Äì11: Synthesis and Dissemination\n\nDraft paper, poster, or industry report with figures and analysis\nPrepare slides and present to faculty, at TechBytes, or a relevant audience\nRevise deliverables based on feedback and prepare for submission"
  },
  {
    "objectID": "projects/sample-project.html#learning-outcomes",
    "href": "projects/sample-project.html#learning-outcomes",
    "title": "Sample Research Project",
    "section": "",
    "text": "Design and execute an applied research study with professional relevance\nGain experience in field-appropriate dissemination and communication\nDevelop evaluation frameworks for AI-in-the-loop tools in computing education\nContribute to the understanding of responsible AI use in real-world learning contexts"
  },
  {
    "objectID": "projects/sample-project.html#final-products",
    "href": "projects/sample-project.html#final-products",
    "title": "Sample Research Project",
    "section": "",
    "text": "A dissemination-ready deliverable (e.g., paper, white paper, presentation)\nAnnotated dataset and reproducible experimentation code\nSummary presentation for presenting to faculty and students at TechBytes and/or practitioner audience"
  }
]